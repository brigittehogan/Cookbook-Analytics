{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "- Brigitte Hogan (bwh5v@virginia.edu) & Jason Tiezzi (jbt5am@virginia.edu)  \n",
    "- DS 5001: Exploratory Text Analytics  \n",
    "- April 2020  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = gray>\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook\n",
    "\n",
    "1. Creates a reduced `TFIDF` table; that is, select only the top 5,000 most significant terms.\n",
    "\n",
    "2. Performs PCA on the reduced `TFIDF` \"by hand,\" i.e. create a covariance matrix of features, apply eigen-decomposition, select components, etc. In the process, generate `COMPS`, `LOADINGS`, and `DCM` tables from your results (as in the in-class example).\n",
    "\n",
    "3. Using whatever visualization libraries you can*, inspect the first three components and answer the following questions:\n",
    "\n",
    "    (1) What `LIB` feature (author or genre) does the first principal component (PC) separate?\n",
    "\n",
    "    (2) Based on the first PC, what two novelists are most opposite to (distant from) each other?\n",
    "\n",
    "    (3) Based on the second PC, what two novelists are most opposite to each other?\n",
    "\n",
    "    (4) Based on the third PC, what two novelists are most opposite to each other?\n",
    "\n",
    "    (5) Based on your knowledge of linguistic annotations, what implicit feature do you think accounts for the clear separation of novels in our data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Tables/'\n",
    "OHCO = ['book_id', 'vol_num', 'chap_num', 'recp_num', 'para_num', 'sent_num', 'token_num'] # define OHCO\n",
    "#OHCO = OHCO[:5]\n",
    "RECIPES = ['book', 'chapter'] # alternate OHCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.linalg import norm\n",
    "import plotly_express as px\n",
    "import seaborn as sns\n",
    "from scipy.linalg import eigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='ticks')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def tfidf (token, ohco, bag='CHAPS', count_method='n', item_type='term_id', tf_method='sum', idf_method='standard'):\n",
    "    ## Arguments -----------------------------------------------------------------------------------------\n",
    "    # token (pandas dataframe): must have term_str and term_id or stem_porter\n",
    "    # bag (string) = OHCO_level, either - BOOKS, CHAPS, PARAS, SENTS\n",
    "    # count_method (string): either 'n' (default) for n tokens/ regular or 'c' for distinct tokens/ binary\n",
    "    # item_type (string): type of item to count, either 'term' for terms or 'stem' for stems\n",
    "    # tf_method (string): tf method - sum (default), max, log, double_norm, raw, binary\n",
    "    # idf_method (string): idf method - standard (default), max, or smooth\n",
    "    \n",
    "    ## Create OHCO Dictionary for Bag --------------------------------------------------------------------\n",
    "    #OHCOdict = {\n",
    "    #    \"BOOKS\": ['book_id'],\n",
    "    #    \"CHAPS\": ['book_id', 'chap_num'],\n",
    "    #    \"PARAS\": ['book_id', 'chap_num', 'para_num'],\n",
    "    #    \"SENTS\": ['book_id', 'chap_num', 'para_num', 'sent_num']\n",
    "    #    }\n",
    "    OHCOdict = {\n",
    "        \"BOOKS\": [ohco[0]],\n",
    "        \"CHAPS\": [ohco[0], ohco[1]],\n",
    "        \"PARAS\": [ohco[0], ohco[1], ohco[2]],\n",
    "        \"SENTS\": [ohco[0], ohco[1], ohco[2], ohco[3]]\n",
    "        }\n",
    "    theBag = OHCOdict[bag]\n",
    "    \n",
    "    ## Create Bag-of-Words/Stems -------------------------------------------------------------------------\n",
    "    BOW = token.groupby(theBag + [item_type])[item_type].count().to_frame().rename(columns={item_type:'n'})\n",
    "    \n",
    "    ## Add Binary Count Column ---------------------------------------------------------------------------\n",
    "    BOW['c'] = BOW.n.astype('bool').astype('int')\n",
    "    \n",
    "    ## Create Document Term Frequency Matrix -------------------------------------------------------------\n",
    "    #DTCM = BOW[count_method].unstack().fillna(0)\n",
    "    DTCM = BOW[count_method].unstack(fill_value=0) # Raf's\n",
    "    \n",
    "    ## Compute TF ----------------------------------------------------------------------------------------\n",
    "    if tf_method == 'sum':\n",
    "        TF = DTCM.T / DTCM.T.sum()\n",
    "    elif tf_method == 'max':\n",
    "        TF = DTCM.T / DTCM.T.max()\n",
    "    elif tf_method == 'log':\n",
    "        TF = np.log10(1 + DTCM.T)\n",
    "    elif tf_method == 'raw':\n",
    "        TF = DTCM.T\n",
    "    elif tf_method == 'double_norm':\n",
    "        tf_norm_k = .5\n",
    "        TF = DTCM.T / DTCM.T.max()\n",
    "        TF = tf_norm_k + (1 - tf_norm_k) * TF[TF > 0]\n",
    "    elif tf_method == 'binary':\n",
    "        TF = DTCM.T.astype('bool').astype('int')\n",
    "    \n",
    "    ## Compute IDF ---------------------------------------------------------------------------------------\n",
    "    N = DTCM.shape[0]\n",
    "    DF = DTCM[DTCM > 0].count()   \n",
    "    \n",
    "    if idf_method == 'standard':\n",
    "        IDF = np.log10(N / DF)\n",
    "    elif idf_method == 'max':\n",
    "        IDF = np.log10(DF.max() / DF) \n",
    "    elif idf_method == 'smooth':\n",
    "        IDF = np.log10((1 + N) / (1 + DF)) + 1 \n",
    "\n",
    "    ## Compute TFIDF -------------------------------------------------------------------------------------\n",
    "    TFIDF = TF.T * IDF\n",
    "    \n",
    "    return TFIDF\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_tfidf(TOKEN, bag=CHAPS, count_method='n', tf_method='sum', idf_method='standard', item_type='term_id'):\n",
    "    \n",
    "    # Create bag of items (terms or stems)\n",
    "    BOW = TOKEN.groupby(bag + [item_type])[item_type].count().to_frame().rename(columns={item_type:'n'})\n",
    "\n",
    "    # Add binary count column\n",
    "    BOW['c'] = BOW.n.astype('bool').astype('int')\n",
    "    \n",
    "    # Create document-term matrix\n",
    "    DTCM = BOW[count_method].unstack(fill_value=0)#.astype('int')\n",
    "    \n",
    "    # Compute TF\n",
    "    if tf_method == 'sum':\n",
    "        TF = DTCM.T / DTCM.T.sum()\n",
    "    elif tf_method == 'max':\n",
    "        TF = DTCM.T / DTCM.T.max()\n",
    "    elif tf_method == 'log':\n",
    "        TF = np.log10(1 + DTCM.T)\n",
    "    elif tf_method == 'raw':\n",
    "        TF = DTCM.T\n",
    "    elif tf_method == 'double_norm':\n",
    "        TF = DTCM.T / DTCM.T.max()\n",
    "        TF = tf_norm_k + (1 - tf_norm_k) * TF[TF > 0] \n",
    "    elif tf_method == 'binary':\n",
    "        TF = DTCM.T.astype('bool').astype('int')  \n",
    "    \n",
    "    # Compute IDF\n",
    "    N = DTCM.shape[0]\n",
    "    DF = DTCM[DTCM > 0].count()\n",
    "    if idf_method == 'standard':\n",
    "        IDF = np.log10(N / DF)\n",
    "    elif idf_method == 'max':\n",
    "        IDF = np.log10(DF.max() / DF) \n",
    "    elif idf_method == 'smooth':\n",
    "        IDF = np.log10((1 + N) / (1 + DF)) + 1\n",
    "    \n",
    "    # Compute TF-IDF\n",
    "    TFIDF = TF.T * IDF\n",
    "    return TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vis_pcs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_pcs(M, a, b, label='author', prefix='PC'):\n",
    "    fig = px.scatter(M, prefix + str(a), prefix + str(b), \n",
    "                     color=label, \n",
    "                     hover_name='doc', \n",
    "                     marginal_x='box',\n",
    "                     marginal_y='box',\n",
    "                     width=1000, height = 600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB   = pd.read_csv(data_dir + 'LIB.csv')                          # book_id, author_last, book_year, period\n",
    "VOCAB = pd.read_csv(data_dir + 'VOCAB.csv').set_index('term_id')   # term_id, term_str, n, stem_porter, stem_porter\n",
    "#TOKEN = pd.read_csv(data_dir + 'TOKEN.csv')                        # OHCO, pos, token_str, term_str, (term_id)\n",
    "TOKENS = pd.read_csv(data_dir + 'TOKEN2.csv')                      # OHCO, pos, token_str, term_str, term_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_book = pd.read_csv(data_dir + 'TFIDF_book.csv')                     # period, book_year, book_id\n",
    "TFIDF_recp = pd.read_csv(data_dir + 'TFIDF_recp.csv')                     #\n",
    "TFIDF_time = pd.read_csv(data_dir + 'TFIDF_timeperiod.csv')               # period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB = LIB.set_index('book_id')\n",
    "TOKENS = TOKENS.set_index(OHCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_last</th>\n",
       "      <th>author_full</th>\n",
       "      <th>book_year</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_file</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>Cookbooks\\WIDAS</td>\n",
       "      <td>Woman's Institute of Domestic Arts and Sciences</td>\n",
       "      <td>1923</td>\n",
       "      <td>Woman's Institute Library of Cookery, Vol. 1</td>\n",
       "      <td>Cookbooks\\WIDAS1923_WILCV01_pg9935.txt</td>\n",
       "      <td>1900s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9936</th>\n",
       "      <td>Cookbooks\\WIDAS</td>\n",
       "      <td>Woman's Institute of Domestic Arts and Sciences</td>\n",
       "      <td>1923</td>\n",
       "      <td>Woman's Institute Library of Cookery, Vol. 2</td>\n",
       "      <td>Cookbooks\\WIDAS1923_WILCV02_pg9936.txt</td>\n",
       "      <td>1900s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9937</th>\n",
       "      <td>Cookbooks\\WIDAS</td>\n",
       "      <td>Woman's Institute of Domestic Arts and Sciences</td>\n",
       "      <td>1923</td>\n",
       "      <td>Woman's Institute Library of Cookery, Vol. 3</td>\n",
       "      <td>Cookbooks\\WIDAS1923_WILCV03_pg9937.txt</td>\n",
       "      <td>1900s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9938</th>\n",
       "      <td>Cookbooks\\WIDAS</td>\n",
       "      <td>Woman's Institute of Domestic Arts and Sciences</td>\n",
       "      <td>1923</td>\n",
       "      <td>Woman's Institute Library of Cookery, Vol. 4</td>\n",
       "      <td>Cookbooks\\WIDAS1923_WILCV04_pg9938.txt</td>\n",
       "      <td>1900s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9939</th>\n",
       "      <td>Cookbooks\\WIDAS</td>\n",
       "      <td>Woman's Institute of Domestic Arts and Sciences</td>\n",
       "      <td>1923</td>\n",
       "      <td>Woman's Institute Library of Cookery, Vol. 5</td>\n",
       "      <td>Cookbooks\\WIDAS1923_WILCV05_pg9939.txt</td>\n",
       "      <td>1900s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_last                                      author_full  \\\n",
       "book_id                                                                     \n",
       "9935     Cookbooks\\WIDAS  Woman's Institute of Domestic Arts and Sciences   \n",
       "9936     Cookbooks\\WIDAS  Woman's Institute of Domestic Arts and Sciences   \n",
       "9937     Cookbooks\\WIDAS  Woman's Institute of Domestic Arts and Sciences   \n",
       "9938     Cookbooks\\WIDAS  Woman's Institute of Domestic Arts and Sciences   \n",
       "9939     Cookbooks\\WIDAS  Woman's Institute of Domestic Arts and Sciences   \n",
       "\n",
       "         book_year                                    book_title  \\\n",
       "book_id                                                            \n",
       "9935          1923  Woman's Institute Library of Cookery, Vol. 1   \n",
       "9936          1923  Woman's Institute Library of Cookery, Vol. 2   \n",
       "9937          1923  Woman's Institute Library of Cookery, Vol. 3   \n",
       "9938          1923  Woman's Institute Library of Cookery, Vol. 4   \n",
       "9939          1923  Woman's Institute Library of Cookery, Vol. 5   \n",
       "\n",
       "                                      book_file period  \n",
       "book_id                                                 \n",
       "9935     Cookbooks\\WIDAS1923_WILCV01_pg9935.txt  1900s  \n",
       "9936     Cookbooks\\WIDAS1923_WILCV02_pg9936.txt  1900s  \n",
       "9937     Cookbooks\\WIDAS1923_WILCV03_pg9937.txt  1900s  \n",
       "9938     Cookbooks\\WIDAS1923_WILCV04_pg9938.txt  1900s  \n",
       "9939     Cookbooks\\WIDAS1923_WILCV05_pg9939.txt  1900s  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>term_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>vol_num</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>recp_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">9935</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1.0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>('1', 'CD')</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>('Without', 'IN')</td>\n",
       "      <td>IN</td>\n",
       "      <td>Without</td>\n",
       "      <td>without</td>\n",
       "      <td>16577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('doubt', 'NN')</td>\n",
       "      <td>NN</td>\n",
       "      <td>doubt</td>\n",
       "      <td>doubt</td>\n",
       "      <td>5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('the', 'DT')</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>15108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('greatest', 'JJS')</td>\n",
       "      <td>JJS</td>\n",
       "      <td>greatest</td>\n",
       "      <td>greatest</td>\n",
       "      <td>7253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         pos_tuple  \\\n",
       "book_id vol_num chap_num recp_num para_num sent_num token_num                        \n",
       "9935    1       1        1.0      0        0        0                  ('1', 'CD')   \n",
       "                                           1        0            ('Without', 'IN')   \n",
       "                                                    1              ('doubt', 'NN')   \n",
       "                                                    3                ('the', 'DT')   \n",
       "                                                    4          ('greatest', 'JJS')   \n",
       "\n",
       "                                                               pos token_str  \\\n",
       "book_id vol_num chap_num recp_num para_num sent_num token_num                  \n",
       "9935    1       1        1.0      0        0        0           CD         1   \n",
       "                                           1        0           IN   Without   \n",
       "                                                    1           NN     doubt   \n",
       "                                                    3           DT       the   \n",
       "                                                    4          JJS  greatest   \n",
       "\n",
       "                                                               term_str  \\\n",
       "book_id vol_num chap_num recp_num para_num sent_num token_num             \n",
       "9935    1       1        1.0      0        0        0                 1   \n",
       "                                           1        0           without   \n",
       "                                                    1             doubt   \n",
       "                                                    3               the   \n",
       "                                                    4          greatest   \n",
       "\n",
       "                                                               term_id  \n",
       "book_id vol_num chap_num recp_num para_num sent_num token_num           \n",
       "9935    1       1        1.0      0        0        0               14  \n",
       "                                           1        0            16577  \n",
       "                                                    1             5252  \n",
       "                                                    3            15108  \n",
       "                                                    4             7253  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>has_int</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>stem_snowball</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15108</th>\n",
       "      <td>the</td>\n",
       "      <td>60407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10502</th>\n",
       "      <td>of</td>\n",
       "      <td>35149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>and</td>\n",
       "      <td>33319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>a</td>\n",
       "      <td>28726</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8071</th>\n",
       "      <td>in</td>\n",
       "      <td>22204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str      n  num  has_int  stop stem_porter stem_snowball\n",
       "term_id                                                              \n",
       "15108        the  60407    0        0     1         the           the\n",
       "10502         of  35149    0        0     1          of            of\n",
       "1546         and  33319    0        0     1         and           and\n",
       "1062           a  28726    0        0     1           a             a\n",
       "8071          in  22204    0        0     1          in            in"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>book_year</th>\n",
       "      <th>book_id</th>\n",
       "      <th>0</th>\n",
       "      <th>000</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>020</th>\n",
       "      <th>...</th>\n",
       "      <th>œuvre</th>\n",
       "      <th>καλον</th>\n",
       "      <th>τεμνω</th>\n",
       "      <th>το</th>\n",
       "      <th>ἁ</th>\n",
       "      <th>⅓</th>\n",
       "      <th>⅔</th>\n",
       "      <th>⅕</th>\n",
       "      <th>⅙</th>\n",
       "      <th>⅜</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900s</td>\n",
       "      <td>1909</td>\n",
       "      <td>19077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900s</td>\n",
       "      <td>1918</td>\n",
       "      <td>15464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1900s</td>\n",
       "      <td>1918</td>\n",
       "      <td>32472</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1900s</td>\n",
       "      <td>1923</td>\n",
       "      <td>9935</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1900s</td>\n",
       "      <td>1923</td>\n",
       "      <td>9936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  period  book_year  book_id         0  000  001  002        01        02  \\\n",
       "0  1900s       1909    19077  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
       "1  1900s       1918    15464  0.000000  0.0  0.0  0.0  0.000045  0.000103   \n",
       "2  1900s       1918    32472  0.000281  0.0  0.0  0.0  0.000000  0.000000   \n",
       "3  1900s       1923     9935  0.000010  0.0  0.0  0.0  0.000000  0.000000   \n",
       "4  1900s       1923     9936  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
       "\n",
       "   020  ...  œuvre  καλον  τεμνω   το    ἁ    ⅓    ⅔    ⅕    ⅙    ⅜  \n",
       "0  0.0  ...    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  ...    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  ...    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  ...    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  ...    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 16789 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_book.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = VOCAB[~VOCAB.term_str.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Max POS to VOCAB table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['pos_max'] = TOKENS.groupby(['term_id', 'pos']).pos.count().unstack().idxmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Term Rank to VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'term_rank' not in VOCAB.columns:\n",
    "    VOCAB = VOCAB.sort_values('n', ascending=False).reset_index()\n",
    "    VOCAB.index.name = 'term_rank'\n",
    "    VOCAB = VOCAB.reset_index()\n",
    "    VOCAB = VOCAB.set_index('term_id')\n",
    "    VOCAB['term_rank'] = VOCAB['term_rank'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Alternate Term Rank to VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rank = VOCAB.n.value_counts()\\\n",
    "    .sort_index(ascending=False).reset_index().reset_index()\\\n",
    "    .rename(columns={'level_0':'term_rank2', 'index':'n', 'n':'nn'})\\\n",
    "    .set_index('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['term_rank2'] = VOCAB.n.map(new_rank.term_rank2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['p'] = VOCAB.n / VOCAB.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Zipf's K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['zipf_k'] = VOCAB.n * VOCAB.term_rank\n",
    "VOCAB['zipf_k2'] = VOCAB.n * VOCAB.term_rank2\n",
    "VOCAB['zipf_k3'] = VOCAB.p * VOCAB.term_rank2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_rank</th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>has_int</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>stem_snowball</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>term_rank2</th>\n",
       "      <th>p</th>\n",
       "      <th>zipf_k</th>\n",
       "      <th>zipf_k2</th>\n",
       "      <th>zipf_k3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15108</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>60407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>1</td>\n",
       "      <td>3.598654</td>\n",
       "      <td>60407</td>\n",
       "      <td>60407</td>\n",
       "      <td>3.598654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10502</th>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>35149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "      <td>2.093947</td>\n",
       "      <td>70298</td>\n",
       "      <td>70298</td>\n",
       "      <td>4.187895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>3</td>\n",
       "      <td>and</td>\n",
       "      <td>33319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "      <td>1.984928</td>\n",
       "      <td>99957</td>\n",
       "      <td>99957</td>\n",
       "      <td>5.954784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>28726</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "      <td>4</td>\n",
       "      <td>1.711307</td>\n",
       "      <td>114904</td>\n",
       "      <td>114904</td>\n",
       "      <td>6.845228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8071</th>\n",
       "      <td>5</td>\n",
       "      <td>in</td>\n",
       "      <td>22204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>5</td>\n",
       "      <td>1.322769</td>\n",
       "      <td>111020</td>\n",
       "      <td>111020</td>\n",
       "      <td>6.613845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_rank term_str      n  num  has_int  stop stem_porter  \\\n",
       "term_id                                                              \n",
       "15108            1      the  60407    0        0     1         the   \n",
       "10502            2       of  35149    0        0     1          of   \n",
       "1546             3      and  33319    0        0     1         and   \n",
       "1062             4        a  28726    0        0     1           a   \n",
       "8071             5       in  22204    0        0     1          in   \n",
       "\n",
       "        stem_snowball pos_max  term_rank2         p  zipf_k  zipf_k2   zipf_k3  \n",
       "term_id                                                                         \n",
       "15108             the      DT           1  3.598654   60407    60407  3.598654  \n",
       "10502              of      IN           2  2.093947   70298    70298  4.187895  \n",
       "1546              and      CC           3  1.984928   99957    99957  5.954784  \n",
       "1062                a      DT           4  1.711307  114904   114904  6.845228  \n",
       "8071               in      IN           5  1.322769  111020   111020  6.613845  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>book_year</th>\n",
       "      <th>book_id</th>\n",
       "      <th>0</th>\n",
       "      <th>000</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>020</th>\n",
       "      <th>...</th>\n",
       "      <th>œuvre</th>\n",
       "      <th>καλον</th>\n",
       "      <th>τεμνω</th>\n",
       "      <th>το</th>\n",
       "      <th>ἁ</th>\n",
       "      <th>⅓</th>\n",
       "      <th>⅔</th>\n",
       "      <th>⅕</th>\n",
       "      <th>⅙</th>\n",
       "      <th>⅜</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900s</td>\n",
       "      <td>1909</td>\n",
       "      <td>19077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900s</td>\n",
       "      <td>1918</td>\n",
       "      <td>15464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1900s</td>\n",
       "      <td>1918</td>\n",
       "      <td>32472</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1900s</td>\n",
       "      <td>1923</td>\n",
       "      <td>9935</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1900s</td>\n",
       "      <td>1923</td>\n",
       "      <td>9936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  period  book_year  book_id         0  000  001  002        01        02  \\\n",
       "0  1900s       1909    19077  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
       "1  1900s       1918    15464  0.000000  0.0  0.0  0.0  0.000045  0.000103   \n",
       "2  1900s       1918    32472  0.000281  0.0  0.0  0.0  0.000000  0.000000   \n",
       "3  1900s       1923     9935  0.000010  0.0  0.0  0.0  0.000000  0.000000   \n",
       "4  1900s       1923     9936  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
       "\n",
       "   020  ...  œuvre  καλον  τεμνω   το    ἁ    ⅓    ⅔    ⅕    ⅙    ⅜  \n",
       "0  0.0  ...    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  ...    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  ...    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  ...    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  ...    0.0    0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 16789 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_book.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add TFIDF sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16786, 14)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16789,)\n",
      "(16792,)\n",
      "(16787,)\n"
     ]
    }
   ],
   "source": [
    "print(TFIDF_book.sum().shape)\n",
    "print(TFIDF_recp.sum().shape)\n",
    "print(TFIDF_time.sum().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['tfidf_sum_book'] = TFIDF_book.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['tfidf_sum_recp'] = TFIDF_recp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['tfidf_sum_perd'] = TFIDF_time.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create reduced TFIDF Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Top 5,000 Significant Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using tfidf_sum for significance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tfidf_sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1de839744cfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVOCAB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVOCAB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tfidf_sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   5006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5007\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5008\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5010\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1772\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1774\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tfidf_sum'"
     ]
    }
   ],
   "source": [
    "VOCAB = VOCAB.sort_values('tfidf_sum', ascending=False)[0:5000].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = TOKEN[TOKEN.term_id.isin(VOCAB.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF = TFIDF.loc[:, TFIDF.columns.isin(VOCAB.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 5000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF.shape  # reduced TFIDF, just significant vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process TFIDF Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize doc vector lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF = TFIDF.apply(lambda x: x / norm(x, 2), 1) # L2 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COV = TFIDF.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COV.iloc[:5,:10].style.background_gradient() # limit this so it doesn't crash your system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose the Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time eig_vals, eig_vecs = eigh(COV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert eigen data to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERM_IDX = COV.index # for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIG_VEC = pd.DataFrame(eig_vecs, index=TERM_IDX, columns=TERM_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIG_VAL = pd.DataFrame(eig_vals, index=TERM_IDX, columns=['eig_val'])\n",
    "EIG_VAL.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIG_VEC.iloc[:5, :10].style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIG_VAL.iloc[:5] # this is the ranking principal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Principal Components\n",
    "\n",
    "Associate each eigenvalue with its corresponding *column* in the eigenvalue matrix by transposing the  `EIG_VEC` dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine eigenvalues and eignvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIG_PAIRS = EIG_VAL.join(EIG_VEC.T) # join into table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIG_PAIRS.head()                    # term_ids ~ components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and Show Explained Variance\n",
    "\n",
    "We might have usd this value to sort our components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIG_PAIRS['exp_var'] = np.round((EIG_PAIRS.eig_val / EIG_PAIRS.eig_val.sum()) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIG_PAIRS.exp_var.sort_values(ascending=False).head().plot.bar(rot=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick Top 3 Components\n",
    "\n",
    "We pick these based on explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPS = EIG_PAIRS.sort_values('exp_var', ascending=False).head(3).reset_index(drop=True)\n",
    "COMPS.index.name = 'comp_id'\n",
    "COMPS.index = [\"PC{}\".format(i) for i in COMPS.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPS # each term associated with component and weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect terms associated with eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.loc[[int(x) for x in EIG_PAIRS.sort_values('exp_var').head(10).index], 'term_str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADINGS = COMPS[TERM_IDX].T\n",
    "LOADINGS.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADINGS.head(20).style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADINGS['term_str'] = LOADINGS.apply(lambda x: VOCAB.loc[int(x.name)].term_str, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0_pos = LOADINGS.sort_values('PC0', ascending=True).head(10).term_str.str.cat(sep=' ') # looking at max pos and neg for 1st three components\n",
    "l0_neg = LOADINGS.sort_values('PC0', ascending=False).head(10).term_str.str.cat(sep=' ')\n",
    "l1_pos = LOADINGS.sort_values('PC1', ascending=True).head(10).term_str.str.cat(sep=' ')\n",
    "l1_neg = LOADINGS.sort_values('PC1', ascending=False).head(10).term_str.str.cat(sep=' ')\n",
    "l2_pos = LOADINGS.sort_values('PC2', ascending=True).head(10).term_str.str.cat(sep=' ')\n",
    "l2_neg = LOADINGS.sort_values('PC2', ascending=False).head(10).term_str.str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Books PC0+', l0_pos)\n",
    "print('Books PC0-', l0_neg)\n",
    "print('Books PC1+', l1_pos)\n",
    "print('Books PC1-', l1_neg)\n",
    "print('Books PC2+', l2_pos)\n",
    "print('Books PC2-', l2_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Docs onto New Subspace\n",
    "\n",
    "Get Document-Component Matrix (DCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCM = TFIDF.dot(COMPS[TERM_IDX].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCM # each doc/chapter has distribution of components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Labels for Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB = LIB.reset_index()\n",
    "LIB[\"title\"] = LIB.book_id\n",
    "LIB = LIB.set_index('book_id')\n",
    "LIB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCM = DCM.join(LIB[['author','genre_full','title']], on='book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCM['doc'] = DCM.apply(lambda x: \"{}-{}-{}\".format(x.author, x.title, x.name[1]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCM.head(10).style.background_gradient() # Note: Components become features for VOCAB and DOC tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_pcs(DCM, 0, 1) # by author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vis_pcs(DCM, 0, 1, label='genre_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis_pcs(DCM, 0, 1, label='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_pcs(DCM, 1, 2) # by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_pcs(DCM, 1, 2, label='genre_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis_pcs(DCM, 1, 2, label='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC 0 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_pcs(DCM, 0, 2) # author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_pcs(DCM, 0, 2, label='genre_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis_pcs(DCM, 0, 2, label='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results\n",
    "\n",
    "**1. What `LIB` feature (author or genre) does the first principal component (PC) separate?**  \n",
    "The first principal component (PC0) separates primarily on genre. The second principal component (PC1) does a better job of separating author. \n",
    "\n",
    "**2. Based on the first PC (PC0), what two novelists are most opposite to (distant from) each other?**  \n",
    "Radcliffe & Christie\n",
    "\n",
    "**3. Based on the second PC (PC1), what two novelists are most opposite to each other?**  \n",
    "Austen & Christie\n",
    "\n",
    "**4. Based on the third PC (PC2), what two novelists are most opposite to each other?**  \n",
    "Collins & Austen\n",
    "\n",
    "**5. Based on your knowledge of linguistic annotations, what implicit feature do you think accounts for the clear separation of novels in our data?**  \n",
    "By looking at the loadings, it appears the novels are being separated by proper nouns, most of which are the names of the principal characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
